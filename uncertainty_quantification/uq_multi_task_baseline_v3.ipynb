{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../ehrshot')\n",
    "import copy\n",
    "from typing import Literal\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Distribution\n",
    "from torch_uncertainty.utils.distributions import cat_dist\n",
    "from torch_uncertainty.routines import ClassificationRoutine\n",
    "# from torch_uncertainty.utils import TUTrainer\n",
    "from lightning.pytorch import Trainer\n",
    "from torch_uncertainty.models import deep_ensembles, mc_dropout\n",
    "from torch_uncertainty.transforms import RepeatTarget\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lightning.pytorch import LightningModule\n",
    "\n",
    "from torch_uncertainty.metrics.classification import BrierScore, CategoricalNLL\n",
    "from torch_uncertainty.metrics.classification.adaptive_calibration_error import BinaryAdaptiveCalibrationError\n",
    "\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "unique_tasks_1 = ['value_los', 'value_icu']\n",
    "unique_tasks_2 = ['value_hypoglycemia', 'value_hyperkalemia', 'value_hyponatremia', 'value_anemia', 'value_thrombocytopenia']\n",
    "unique_tasks_3 = ['value_new_hypertension', 'value_new_hyperlipidemia', 'value_new_acutemi']\n",
    "\n",
    "\n",
    "all_tasks = [unique_tasks_1, unique_tasks_2, unique_tasks_3]\n",
    "all_tasks_name = ['general_operation_v1', 'lab_test', 'new_diagnose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc21 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout21 = nn.Dropout(p=0.2)\n",
    "        self.fc31 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        self.fc22 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout22 = nn.Dropout(p=0.2)\n",
    "        self.fc32 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x1 = F.relu(self.fc21(x))\n",
    "        x1 = self.dropout21(x1)\n",
    "        x1 = self.fc31(x1)\n",
    "\n",
    "        x2 = F.relu(self.fc22(x))\n",
    "        x2 = self.dropout22(x2)\n",
    "        x2 = self.fc32(x2)\n",
    "\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, weight_list, num_epochs=100, lr_mult=1):\n",
    "    criterion1 = nn.CrossEntropyLoss(weight = weight_list[0])\n",
    "    criterion2 = nn.CrossEntropyLoss(weight = weight_list[1])\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01 * lr_mult, momentum=0.9)\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        for data, target1, target2, in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss1 = criterion1(outputs[0], target1)\n",
    "            loss2 = criterion2(outputs[1], target2)\n",
    "            total_loss = loss1 + loss2\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target1, target2 in val_loader:\n",
    "                outputs = model(data)\n",
    "                loss1 = criterion1(outputs[0], target1)\n",
    "                loss2 = criterion2(outputs[1], target2)\n",
    "                total_val_loss += loss1.item() + loss2.item()\n",
    "        \n",
    "        average_val_loss = total_val_loss / len(val_loader)\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(f'Epoch {epoch+1}: Avg Val Loss: {average_val_loss:.4f}')\n",
    "\n",
    "    return model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/tmp/ipykernel_171572/3595705383.py:45: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)\n",
      "  y_train = torch.tensor(y_train).long().T\n",
      "100%|██████████| 2/2 [00:00<00:00, 112.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Avg Val Loss: 1.0723\n",
      "Epoch 3: Avg Val Loss: 1.0211\n",
      "Epoch 5: Avg Val Loss: 1.0593\n",
      "Epoch 7: Avg Val Loss: 1.2705\n",
      "Epoch 9: Avg Val Loss: 1.2195\n",
      "Epoch 11: Avg Val Loss: 1.7397\n",
      "Epoch 13: Avg Val Loss: 1.5661\n",
      "Epoch 15: Avg Val Loss: 1.8153\n",
      "Epoch 17: Avg Val Loss: 2.1512\n",
      "Epoch 19: Avg Val Loss: 2.3695\n",
      "Epoch 21: Avg Val Loss: 1.9653\n",
      "Epoch 23: Avg Val Loss: 2.3833\n",
      "Epoch 25: Avg Val Loss: 2.2461\n",
      "Epoch 27: Avg Val Loss: 2.3698\n",
      "Epoch 29: Avg Val Loss: 3.0609\n",
      "Epoch 31: Avg Val Loss: 3.6845\n",
      "Epoch 33: Avg Val Loss: 2.6466\n",
      "Epoch 35: Avg Val Loss: 2.8877\n",
      "Epoch 37: Avg Val Loss: 2.3694\n",
      "Epoch 39: Avg Val Loss: 2.7159\n",
      "Epoch 41: Avg Val Loss: 3.0551\n",
      "Epoch 43: Avg Val Loss: 2.3862\n",
      "Epoch 45: Avg Val Loss: 2.8843\n",
      "Epoch 47: Avg Val Loss: 3.3995\n",
      "Epoch 49: Avg Val Loss: 3.2771\n",
      "Epoch 51: Avg Val Loss: 3.0651\n",
      "Epoch 53: Avg Val Loss: 3.3066\n",
      "Epoch 55: Avg Val Loss: 3.3818\n",
      "Epoch 57: Avg Val Loss: 3.3694\n",
      "Epoch 59: Avg Val Loss: 3.7250\n",
      "Epoch 61: Avg Val Loss: 3.5283\n",
      "Epoch 63: Avg Val Loss: 3.8328\n",
      "Epoch 65: Avg Val Loss: 4.2394\n",
      "Epoch 67: Avg Val Loss: 3.6979\n",
      "Epoch 69: Avg Val Loss: 4.3144\n",
      "Epoch 71: Avg Val Loss: 4.4627\n",
      "Epoch 73: Avg Val Loss: 4.8807\n",
      "Epoch 75: Avg Val Loss: 4.5862\n",
      "Epoch 77: Avg Val Loss: 4.1289\n",
      "Epoch 79: Avg Val Loss: 4.1179\n",
      "Epoch 81: Avg Val Loss: 4.7075\n",
      "Epoch 83: Avg Val Loss: 4.5144\n",
      "Epoch 85: Avg Val Loss: 4.5569\n",
      "Epoch 87: Avg Val Loss: 4.5521\n",
      "Epoch 89: Avg Val Loss: 4.7294\n",
      "Epoch 91: Avg Val Loss: 3.9707\n",
      "Epoch 93: Avg Val Loss: 4.1176\n",
      "Epoch 95: Avg Val Loss: 4.0722\n",
      "Epoch 97: Avg Val Loss: 4.1579\n",
      "Epoch 99: Avg Val Loss: 4.5903\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "# for i in tqdm(range(len(all_tasks))):\n",
    "# for i in [0]:\n",
    "i = 0\n",
    "general_task_name = all_tasks_name[i]\n",
    "\n",
    "folder_path = f'same_time_data/{general_task_name}'\n",
    "\n",
    "train_x_name = os.path.join(folder_path, 'x_train.csv')\n",
    "train_y_name = os.path.join(folder_path, 'y_train.csv')\n",
    "val_x_name = os.path.join(folder_path, 'x_val.csv')\n",
    "val_y_name = os.path.join(folder_path, 'y_val.csv')\n",
    "test_x_name = os.path.join(folder_path, 'x_test.csv')\n",
    "test_y_name = os.path.join(folder_path, 'y_test.csv')\n",
    "\n",
    "X_train = pd.read_csv(train_x_name).to_numpy()\n",
    "X_val = pd.read_csv(val_x_name).to_numpy()\n",
    "X_test = pd.read_csv(test_x_name).to_numpy()\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "X_val = torch.tensor(X_val).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "y_test_list = []\n",
    "\n",
    "class_weights_list = []\n",
    "\n",
    "for j in tqdm(range(len(all_tasks[i]))):\n",
    "# for j in range(1):\n",
    "    specific_task_name = all_tasks[i][j]\n",
    "    y_train = pd.read_csv(train_y_name)[specific_task_name].astype(int).to_numpy()\n",
    "    y_val = pd.read_csv(val_y_name)[specific_task_name].astype(int).to_numpy()\n",
    "    y_test = pd.read_csv(test_y_name)[specific_task_name].astype(int).to_numpy()\n",
    "\n",
    "    assert len(np.unique(y_train)) == 2\n",
    "    # Create class weights\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "    class_weights_list.append(class_weights)\n",
    "    \n",
    "    y_train = torch.tensor(y_train).long().T\n",
    "    y_val = torch.tensor(y_val).long().T\n",
    "    y_test = torch.tensor(y_test).long().T\n",
    "\n",
    "    # Create TensorDatasets\n",
    "    y_train_list.append(y_train)\n",
    "    y_val_list.append(y_val)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train_list[0], y_train_list[1])\n",
    "val_dataset = TensorDataset(X_val, y_val_list[0], y_val_list[1])\n",
    "test_dataset = TensorDataset(X_test, y_test_list[0], y_test_list[1])\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = MultiTaskModel(X_train.shape[1], 128, 2)\n",
    "\n",
    "best_model = train_and_validate(model, train_dl, val_dl, class_weights_list, num_epochs=max_epochs, lr_mult=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = MultiTaskModel(X_train.shape[1], 128, 2)\n",
    "new_model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    preds_prob = []\n",
    "    probs = []\n",
    "    gts = []\n",
    "    with torch.no_grad():\n",
    "        correct1 = 0\n",
    "        total1 = 0\n",
    "        for inputs, labels1, labels2 in test_loader:\n",
    "            # inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs1, outputs2 = model(inputs)\n",
    "            probabilities1 = torch.softmax(outputs1.data, dim=1)\n",
    "            predicted1 = torch.argmax(probabilities1, dim=1)\n",
    "            predicted_probabilities1 = probabilities1[torch.arange(probabilities1.shape[0]), predicted1]\n",
    "\n",
    "            total1 += labels1.size(0)\n",
    "            correct1 += (predicted1 == labels1).sum().item()\n",
    "\n",
    "            preds.extend(list(predicted1.cpu().numpy()))\n",
    "            gts.extend(list(labels1.cpu().numpy()))\n",
    "            preds_prob.extend(list(predicted_probabilities1.cpu().numpy()))\n",
    "            probs.extend(list(probabilities1.cpu().numpy()))\n",
    "\n",
    "        test_accuracy1 = 100 * correct1 / total1\n",
    "        print(f'Test Accuracy: {test_accuracy1:.3f}%')\n",
    "        auc_score1 = roc_auc_score(gts, preds)\n",
    "        print(f'AUC Score: {auc_score1:.3f}')\n",
    "            \n",
    "    # return test_accuracy, auc_score * 100, ave_preds_prob, gts, preds, preds_prob, probs\n",
    "    return gts, preds, preds_prob, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_brier_score(gt, binary_prob):\n",
    "    metric_brier = BrierScore(num_classes=2, top_class=False)\n",
    "    metric_brier.update(torch.tensor(binary_prob), torch.tensor(gt))\n",
    "    brierScore = metric_brier.compute()\n",
    "    return np.round(brierScore.item(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.761%\n",
      "AUC Score: 0.674\n"
     ]
    }
   ],
   "source": [
    "gts, preds, preds_prob, probs = evaluate_model(new_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171572/3484339361.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  metric_brier.update(torch.tensor(binary_prob), torch.tensor(gt))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.388"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcualte_brier_score(np.array(gts), probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:uq_ehr]",
   "language": "python",
   "name": "conda-env-uq_ehr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
