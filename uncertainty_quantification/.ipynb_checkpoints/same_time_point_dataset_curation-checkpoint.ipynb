{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../ehrshot')\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "# from utils import (\n",
    "#     LABELING_FUNCTION_2_PAPER_NAME,\n",
    "#     SHOT_STRATS,\n",
    "#     MODEL_2_INFO,\n",
    "#     get_labels_and_features, \n",
    "#     process_chexpert_labels, \n",
    "#     convert_multiclass_to_binary_labels,\n",
    "#     CHEXPERT_LABELS, \n",
    "#     LR_PARAMS, \n",
    "#     XGB_PARAMS, \n",
    "#     RF_PARAMS,\n",
    "#     ProtoNetCLMBRClassifier, \n",
    "#     get_patient_splits_by_idx\n",
    "# )\n",
    "\n",
    "\n",
    "# import femr\n",
    "# import femr.datasets\n",
    "# from femr.labelers import load_labeled_patients, LabeledPatients\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(42)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../white_box_common_data/'\n",
    "data_file = ['general_operation_with_index.csv', 'general_operation_with_index_v2.csv','new_diagnose_with_index.csv', 'lab_test_with_index.csv']\n",
    "\n",
    "multi_task_dir = 'same_time_data/'\n",
    "\n",
    "multi_task_name = ['general_operation_v1', 'general_operation_v2','new_diagnose', 'lab_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3617\n",
      "6491\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    f = data_file[0]\n",
    "    temp_df = pd.read_csv(os.path.join(data_dir, f))\n",
    "    print(len(temp_df['patient_id'].unique()))\n",
    "    print(len(temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>value_los</th>\n",
       "      <th>value_icu</th>\n",
       "      <th>feature_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115973157</td>\n",
       "      <td>2022-12-09 23:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115973052</td>\n",
       "      <td>2017-01-08 23:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>398598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115973052</td>\n",
       "      <td>2017-02-11 23:59:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>398603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115973052</td>\n",
       "      <td>2017-04-09 23:59:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>398826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115973052</td>\n",
       "      <td>2017-04-21 23:59:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>398853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>115967235</td>\n",
       "      <td>2017-09-26 23:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>349110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>115967238</td>\n",
       "      <td>2016-04-29 23:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>115967255</td>\n",
       "      <td>2015-04-09 23:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>202594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>115967255</td>\n",
       "      <td>2021-04-20 23:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>202609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>115967264</td>\n",
       "      <td>2019-09-09 23:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6491 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id      prediction_time  value_los  value_icu  feature_index\n",
       "0      115973157  2022-12-09 23:59:00      False      False         241066\n",
       "1      115973052  2017-01-08 23:59:00      False      False         398598\n",
       "2      115973052  2017-02-11 23:59:00       True       True         398603\n",
       "3      115973052  2017-04-09 23:59:00       True      False         398826\n",
       "4      115973052  2017-04-21 23:59:00       True      False         398853\n",
       "...          ...                  ...        ...        ...            ...\n",
       "6486   115967235  2017-09-26 23:59:00      False      False         349110\n",
       "6487   115967238  2016-04-29 23:59:00      False      False          65022\n",
       "6488   115967255  2015-04-09 23:59:00      False      False         202594\n",
       "6489   115967255  2021-04-20 23:59:00      False      False         202609\n",
       "6490   115967264  2019-09-09 23:59:00      False      False          65309\n",
       "\n",
       "[6491 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = pd.read_csv('../EHRSHOT_ASSETS/splits/person_id_map.csv')\n",
    "\n",
    "with open('../EHRSHOT_ASSETS/features/clmbr_features.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "features = data['data_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person_id = df_split.loc[df_split['split'] == 'train', 'omop_person_id'].values\n",
    "test_person_id = df_split.loc[df_split['split'] == 'test', 'omop_person_id'].values\n",
    "val_person_id = df_split.loc[df_split['split'] == 'val', 'omop_person_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_by_split(df, train_person_id, test_person_id, val_person_id):\n",
    "    train_mask = df['patient_id'].isin(train_person_id)\n",
    "    filtered_train_indices = df.index[train_mask]\n",
    "\n",
    "    test_mask = df['patient_id'].isin(test_person_id)\n",
    "    filtered_test_indices = df.index[test_mask]\n",
    "\n",
    "    val_mask = df['patient_id'].isin(val_person_id)\n",
    "    filtered_val_indices = df.index[val_mask]\n",
    "\n",
    "    y_train = df.loc[filtered_train_indices]\n",
    "    y_test = df.loc[filtered_test_indices]\n",
    "    y_val = df.loc[filtered_val_indices]\n",
    "\n",
    "    y_train_index = y_train['feature_index'].values\n",
    "    y_test_index = y_test['feature_index'].values\n",
    "    y_val_index = y_val['feature_index'].values\n",
    "\n",
    "    x_train = pd.DataFrame(features[y_train_index])\n",
    "    x_test = pd.DataFrame(features[y_test_index])\n",
    "    x_val = pd.DataFrame(features[y_val_index])\n",
    "\n",
    "    return x_train, x_test, x_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_file)):\n",
    "\n",
    "    df_name = data_file[i]\n",
    "    df = pd.read_csv(os.path.join(data_dir, df_name))\n",
    "\n",
    "    all_task_dir = os.path.join(multi_task_dir, multi_task_name[i])\n",
    "    if not os.path.exists(all_task_dir):\n",
    "        os.makedirs(all_task_dir)\n",
    "        print(all_task_dir)\n",
    "    x_train, x_test, x_val, y_train, y_test, y_val = get_dataset_by_split(df, train_person_id, test_person_id, val_person_id)\n",
    "#     x_train.to_csv(os.path.join(all_task_dir, 'x_train.csv'), index=False)\n",
    "#     x_test.to_csv(os.path.join(all_task_dir, 'x_test.csv'), index=False)\n",
    "#     x_val.to_csv(os.path.join(all_task_dir, 'x_val.csv'), index=False)\n",
    "#     y_train.to_csv(os.path.join(all_task_dir, 'y_train.csv'), index=False)\n",
    "#     y_test.to_csv(os.path.join(all_task_dir, 'y_test.csv'), index=False)\n",
    "#     y_val.to_csv(os.path.join(all_task_dir, 'y_val.csv'), index=False)\n",
    "    print(y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'same_time_data/lab_test'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_task_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:uq_ehr]",
   "language": "python",
   "name": "conda-env-uq_ehr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
