{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('multi_task_data/X_train_all.csv')\n",
    "X_test = pd.read_csv('multi_task_data/X_test_all.csv')\n",
    "y_train = pd.read_csv('multi_task_data/y_train_all.csv')\n",
    "y_test = pd.read_csv('multi_task_data/y_test_all.csv')\n",
    "y_train['task'] = X_train['task']\n",
    "y_test['task'] = X_test['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task_embeddings.json', 'r') as file:\n",
    "    task_embeddings = json.load(file)\n",
    "task_embedding_dim = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_tasks\n",
    "unique_tasks_1 = ['guo_los', 'guo_readmission', 'guo_icu']\n",
    "unique_tasks_2 = ['new_hypertension', 'new_hyperlipidemia', 'new_pancan', 'new_celiac', 'new_lupus', 'new_acutemi']\n",
    "unique_tasks_3 = ['lab_thrombocytopenia', 'lab_hyperkalemia', 'lab_hyponatremia', 'lab_anemia', 'lab_hypoglycemia']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_embeddings(df, task_embeddings):\n",
    "    embeddings = df['task'].map(task_embeddings)\n",
    "    new_columns = [f'task_emb_{i}' for i in range(task_embedding_dim)]\n",
    "    df = pd.concat([df.drop('task', axis=1), pd.DataFrame(embeddings.tolist(), columns=new_columns, index=df.index)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[X_train['task'].isin(unique_tasks_1)]\n",
    "X_train = X_train.drop(columns=['Unnamed: 0'])\n",
    "X_test = X_test[X_test['task'].isin(unique_tasks_1)]\n",
    "X_test = X_test.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "y_train = y_train[y_train['task'].isin(unique_tasks_1)]\n",
    "y_train = y_train.drop(columns=['Unnamed: 0'])\n",
    "y_test = y_test[y_test['task'].isin(unique_tasks_1)]\n",
    "y_test = y_test.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# X_train = X_train[X_train['task'].isin(unique_tasks_2)]\n",
    "# X_train = X_train.drop(columns=['Unnamed: 0'])\n",
    "# X_test = X_test[X_test['task'].isin(unique_tasks_2)]\n",
    "# X_test = X_test.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# y_train = y_train[y_train['task'].isin(unique_tasks_2)]\n",
    "# y_train = y_train.drop(columns=['Unnamed: 0'])\n",
    "# y_test = y_test[y_test['task'].isin(unique_tasks_2)]\n",
    "# y_test = y_test.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# X_train = X_train[X_train['task'].isin(unique_tasks_3)]\n",
    "# X_train = X_train.drop(columns=['Unnamed: 0'])\n",
    "# X_test = X_test[X_test['task'].isin(unique_tasks_3)]\n",
    "# X_test = X_test.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# y_train = y_train[y_train['task'].isin(unique_tasks_3)]\n",
    "# y_train = y_train.drop(columns=['Unnamed: 0'])\n",
    "# y_test = y_test[y_test['task'].isin(unique_tasks_3)]\n",
    "# y_test = y_test.drop(columns=['Unnamed: 0'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = expand_embeddings(X_train, task_embeddings)\n",
    "X_test_1 = expand_embeddings(X_test, task_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1 = y_train[y_train['task'].isin(unique_tasks_1)]['0'].values\n",
    "y_test_1 = y_test[y_test['task'].isin(unique_tasks_1)]['0'].values\n",
    "\n",
    "# y_train_1 = y_train[y_train['task'].isin(unique_tasks_2)]['0'].values\n",
    "# y_test_1 = y_test[y_test['task'].isin(unique_tasks_2)]['0'].values\n",
    "\n",
    "# y_train_1 = y_train[y_train['task'].isin(unique_tasks_3)]['0'].values\n",
    "# y_test_1 = y_test[y_test['task'].isin(unique_tasks_3)]['0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train_1.to_numpy()\n",
    "X_test_1 = X_test_1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(num_epochs, model, train_loader, val_loader, criterion, optimizer):\n",
    "#     val_accuracy_current = 0\n",
    "#     val_auc = 0\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "#         model.train()\n",
    "#         for inputs, labels in train_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         # Evaluate on validation set\n",
    "#         if epoch % 2 == 0:\n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 preds = []\n",
    "#                 gts = []\n",
    "#                 correct = 0\n",
    "#                 total = 0\n",
    "                \n",
    "#                 for inputs, labels in val_loader:\n",
    "#                     inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                     outputs = model(inputs)\n",
    "#                     _, predicted = torch.max(outputs.data, 1)\n",
    "#                     total += labels.size(0)\n",
    "#                     correct += (predicted == labels).sum().item()\n",
    "#                     preds.extend(list(predicted.cpu().numpy()))\n",
    "#                     gts.extend(list(labels.cpu().numpy()))\n",
    "#                 val_accuracy = 100 * correct / total\n",
    "#                 auc_score = roc_auc_score(gts, preds)\n",
    "                \n",
    "                \n",
    "#                 if auc_score > val_auc:\n",
    "#                     val_auc = auc_score\n",
    "#                     torch.save(model.state_dict(), 'best_model_task1.pth')\n",
    "#                 print(f'Epoch [{epoch+1}/{num_epochs}], Validation Auc: {auc_score:.2f}%')\n",
    "#     return model\n",
    "\n",
    "def train_model(num_epochs, model, train_loader, val_loader, criterion, optimizer, task_name):\n",
    "    val_accuracy_current = 0\n",
    "    val_auc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs.device.type, labels.device.type)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        if epoch % 2 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                preds = []\n",
    "                gts = []\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                \n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    preds.extend(list(predicted.cpu().numpy()))\n",
    "                    gts.extend(list(labels.cpu().numpy()))\n",
    "                val_accuracy = 100 * correct / total\n",
    "                auc_score = roc_auc_score(gts, preds)\n",
    "                \n",
    "                \n",
    "                if auc_score > val_auc:\n",
    "                    val_auc = auc_score\n",
    "                    model_name = f'multi_task_models/best_model_task_{task_name}.pth'\n",
    "                    torch.save(model.state_dict(), model_name)\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Validation Auc: {auc_score:.2f}%')\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, test_loader):\n",
    "#     model.eval()\n",
    "#     preds = []\n",
    "#     preds_prob = []\n",
    "#     gts = []\n",
    "#     with torch.no_grad():\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             # _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "#             probabilities = torch.softmax(outputs.data, dim=1)\n",
    "\n",
    "#             # Get the predicted class for each data point (highest probability)\n",
    "#             predicted = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "#             # Gather the probabilities of the predicted classes\n",
    "#             predicted_probabilities = probabilities[torch.arange(probabilities.shape[0]), predicted]\n",
    "\n",
    "            \n",
    "\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#             preds.extend(list(predicted.cpu().numpy()))\n",
    "#             gts.extend(list(labels.cpu().numpy()))\n",
    "#             preds_prob.extend(list(predicted_probabilities.cpu().numpy()))\n",
    "\n",
    "#         test_accuracy = 100 * correct / total\n",
    "#         print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "#         auc_score = roc_auc_score(gts, preds)\n",
    "#         ave_preds_prob = np.mean(preds_prob)\n",
    "\n",
    "#     return test_accuracy, auc_score * 100, ave_preds_prob\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    preds_prob = []\n",
    "    probs = []\n",
    "    gts = []\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            probabilities = torch.softmax(outputs.data, dim=1)\n",
    "\n",
    "            # Get the predicted class for each data point (highest probability)\n",
    "            predicted = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "            # Gather the probabilities of the predicted classes\n",
    "            predicted_probabilities = probabilities[torch.arange(probabilities.shape[0]), predicted]\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            preds.extend(list(predicted.cpu().numpy()))\n",
    "            gts.extend(list(labels.cpu().numpy()))\n",
    "            preds_prob.extend(list(predicted_probabilities.cpu().numpy()))\n",
    "            probs.extend(list(probabilities.cpu().numpy()))\n",
    "\n",
    "        test_accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "        auc_score = roc_auc_score(gts, preds)\n",
    "        ave_preds_prob = np.mean(preds_prob)\n",
    "\n",
    "    return test_accuracy, auc_score * 100, ave_preds_prob, gts, preds, preds_prob, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_1), y=y_train_1)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Move weights to the same device as model\n",
    "if torch.cuda.is_available():\n",
    "    class_weights = class_weights.to(device=device)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_1 = torch.tensor(X_train_1).float()\n",
    "X_test_1 = torch.tensor(X_test_1).float()\n",
    "y_train_1 = torch.tensor(y_train_1).long()\n",
    "y_test_1 = torch.tensor(y_test_1).long()\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_1, y_train_1)\n",
    "test_dataset = TensorDataset(X_test_1, y_test_1)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train['task'].isin(unique_tasks_2)]['0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/EHRSHOT_ENV/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "Epoch [1/50], Validation Auc: 0.76%\n",
      "Epoch [2/50]\n",
      "Epoch [3/50]\n",
      "Epoch [3/50], Validation Auc: 0.76%\n",
      "Epoch [4/50]\n",
      "Epoch [5/50]\n",
      "Epoch [5/50], Validation Auc: 0.76%\n",
      "Epoch [6/50]\n",
      "Epoch [7/50]\n",
      "Epoch [7/50], Validation Auc: 0.75%\n",
      "Epoch [8/50]\n",
      "Epoch [9/50]\n",
      "Epoch [9/50], Validation Auc: 0.75%\n",
      "Epoch [10/50]\n",
      "Epoch [11/50]\n",
      "Epoch [11/50], Validation Auc: 0.73%\n",
      "Epoch [12/50]\n",
      "Epoch [13/50]\n",
      "Epoch [13/50], Validation Auc: 0.74%\n",
      "Epoch [14/50]\n",
      "Epoch [15/50]\n",
      "Epoch [15/50], Validation Auc: 0.70%\n",
      "Epoch [16/50]\n",
      "Epoch [17/50]\n",
      "Epoch [17/50], Validation Auc: 0.70%\n",
      "Epoch [18/50]\n",
      "Epoch [19/50]\n",
      "Epoch [19/50], Validation Auc: 0.70%\n",
      "Epoch [20/50]\n",
      "Epoch [21/50]\n",
      "Epoch [21/50], Validation Auc: 0.70%\n",
      "Epoch [22/50]\n",
      "Epoch [23/50]\n",
      "Epoch [23/50], Validation Auc: 0.67%\n",
      "Epoch [24/50]\n",
      "Epoch [25/50]\n",
      "Epoch [25/50], Validation Auc: 0.69%\n",
      "Epoch [26/50]\n",
      "Epoch [27/50]\n",
      "Epoch [27/50], Validation Auc: 0.69%\n",
      "Epoch [28/50]\n",
      "Epoch [29/50]\n",
      "Epoch [29/50], Validation Auc: 0.67%\n",
      "Epoch [30/50]\n",
      "Epoch [31/50]\n",
      "Epoch [31/50], Validation Auc: 0.69%\n",
      "Epoch [32/50]\n",
      "Epoch [33/50]\n",
      "Epoch [33/50], Validation Auc: 0.69%\n",
      "Epoch [34/50]\n",
      "Epoch [35/50]\n",
      "Epoch [35/50], Validation Auc: 0.68%\n",
      "Epoch [36/50]\n",
      "Epoch [37/50]\n",
      "Epoch [37/50], Validation Auc: 0.67%\n",
      "Epoch [38/50]\n",
      "Epoch [39/50]\n",
      "Epoch [39/50], Validation Auc: 0.68%\n",
      "Epoch [40/50]\n",
      "Epoch [41/50]\n",
      "Epoch [41/50], Validation Auc: 0.68%\n",
      "Epoch [42/50]\n",
      "Epoch [43/50]\n",
      "Epoch [43/50], Validation Auc: 0.69%\n",
      "Epoch [44/50]\n",
      "Epoch [45/50]\n",
      "Epoch [45/50], Validation Auc: 0.68%\n",
      "Epoch [46/50]\n",
      "Epoch [47/50]\n",
      "Epoch [47/50], Validation Auc: 0.68%\n",
      "Epoch [48/50]\n",
      "Epoch [49/50]\n",
      "Epoch [49/50], Validation Auc: 0.67%\n",
      "Epoch [50/50]\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_1.shape[1]\n",
    "hidden_size = 100  # You can tune this\n",
    "num_classes = len(torch.unique(y_train_1))\n",
    "model = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "model.to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)  # Suitable for classification with imbalanced dataset\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Learning rate can be tuned\n",
    "\n",
    "model = train_model(50, model, train_loader, test_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "# model.load_state_dict(torch.load('best_model_task2.pth'))\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.95%\n",
      "guo_los 77.9498861047836 69.03100108497182 0.9444388\n",
      "Test Accuracy: 85.29%\n",
      "guo_readmission 85.29008679762448 57.37787614148422 0.9664198\n",
      "Test Accuracy: 95.48%\n",
      "guo_icu 95.48355424644085 60.51048698167792 0.99147075\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test.reset_index(drop=True, inplace=False)\n",
    "for task in unique_tasks_1:\n",
    "# for task in unique_tasks_2:\n",
    "# for task in unique_tasks_3:\n",
    "    idx = y_test[y_test['task'].isin([task])].index\n",
    "    X_test_temp = X_test_1[idx]\n",
    "    y_test_temp = y_test_1[idx]\n",
    "    test_temp_dataset = TensorDataset(X_test_temp, y_test_temp)\n",
    "    test_temp_loader = DataLoader(test_temp_dataset, batch_size=batch_size, shuffle=False)\n",
    "    acc_temp, auc_temp, outputs_temp = evaluate_model(model, test_temp_loader)\n",
    "    print(task, acc_temp, auc_temp, outputs_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99147075"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1282978832.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    torch.(outputs_temp.data, )\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "torch.(outputs_temp.data, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "6416    False\n",
       "6417    False\n",
       "6418    False\n",
       "6419    False\n",
       "6420    False\n",
       "Name: task, Length: 6421, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['task'].isin([unique_tasks_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_los</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_los</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_los</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_los</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_los</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_icu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_icu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_icu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_icu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>0</td>\n",
       "      <td>guo_icu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6421 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     task\n",
       "0     0  guo_los\n",
       "1     0  guo_los\n",
       "2     0  guo_los\n",
       "3     0  guo_los\n",
       "4     0  guo_los\n",
       "...  ..      ...\n",
       "6416  0  guo_icu\n",
       "6417  0  guo_icu\n",
       "6418  0  guo_icu\n",
       "6419  0  guo_icu\n",
       "6420  0  guo_icu\n",
       "\n",
       "[6421 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHRSHOT_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
