{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../ehrshot')\n",
    "import copy\n",
    "from typing import Literal\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Distribution\n",
    "from torch_uncertainty.utils.distributions import cat_dist\n",
    "from torch_uncertainty.routines import ClassificationRoutine\n",
    "from torch_uncertainty.utils import TUTrainer\n",
    "from torch_uncertainty.models import deep_ensembles, mc_dropout\n",
    "from torch_uncertainty.transforms import RepeatTarget\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tasks_1 = ['guo_los', 'guo_readmission', 'guo_icu']\n",
    "unique_tasks_2 = ['new_hypertension', 'new_hyperlipidemia', 'new_pancan', 'new_celiac', 'new_lupus', 'new_acutemi']\n",
    "unique_tasks_3 = ['lab_thrombocytopenia', 'lab_hyperkalemia', 'lab_hyponatremia', 'lab_anemia', 'lab_hypoglycemia']\n",
    "\n",
    "all_tasks = [unique_tasks_1, unique_tasks_2, unique_tasks_3]\n",
    "all_tasks_name = ['unique_tasks_1', 'unique_tasks_2', 'unique_tasks_3']\n",
    "\n",
    "labeling_functions=[\n",
    "    \"guo_los\",\n",
    "    \"guo_readmission\",\n",
    "    \"guo_icu\",\n",
    "    \"new_hypertension\",\n",
    "    \"new_hyperlipidemia\",\n",
    "    \"new_pancan\",\n",
    "    \"new_celiac\",\n",
    "    \"new_lupus\",\n",
    "    \"new_acutemi\",\n",
    "    \"lab_thrombocytopenia\",\n",
    "    \"lab_hyperkalemia\",\n",
    "    \"lab_hyponatremia\",\n",
    "    \"lab_anemia\",\n",
    "    \"lab_hypoglycemia\" # will OOM at 200G on `gpu` partition\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_embeddings(df, task_embeddings):\n",
    "    embeddings = df['task'].map(task_embeddings)\n",
    "    new_columns = [f'task_emb_{i}' for i in range(task_embedding_dim)]\n",
    "    df = pd.concat([df.drop('task', axis=1), pd.DataFrame(embeddings.tolist(), columns=new_columns, index=df.index)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task_embeddings.json', 'r') as file:\n",
    "    task_embeddings = json.load(file)\n",
    "task_embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2101942803.py, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 54\u001b[0;36m\u001b[0m\n\u001b[0;31m    pd.DataFrame(X_test).to_csv(os.pa                                                                                                                                                                   th.join(folder_path_data, 'X_test.csv'), index=False)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(labeling_functions)):\n",
    "\n",
    "# for j in range(len(all_tasks)):\n",
    "\n",
    "    X_train_all = []\n",
    "    y_train_all = []\n",
    "    X_val_all = []\n",
    "    y_val_all = []\n",
    "\n",
    "    task_type = all_tasks_name[j]\n",
    "    folder_path_dir = f'multi_task_data_uq_v2/{task_type}'\n",
    "\n",
    "    if not os.path.exists(folder_path_dir):\n",
    "        os.makedirs(folder_path_dir)\n",
    "\n",
    "    unique_tasks = all_tasks[j]\n",
    "\n",
    "    for i in range(len(unique_tasks)):\n",
    "\n",
    "        task = unique_tasks[i]\n",
    "        folder_path_data = f'multi_task_data_uq/{task_type}/{task}'\n",
    "        folder_path = f'single_task_data/{task}'\n",
    "\n",
    "        if not os.path.exists(folder_path_data):\n",
    "            os.makedirs(folder_path_data)\n",
    "\n",
    "        train_x_name = os.path.join(folder_path, 'X_train.csv')\n",
    "        train_y_name = os.path.join(folder_path, 'y_train.csv')\n",
    "        val_x_name = os.path.join(folder_path, 'X_val.csv')\n",
    "        val_y_name = os.path.join(folder_path, 'y_val.csv')\n",
    "        test_x_name = os.path.join(folder_path, 'X_test.csv')\n",
    "        test_y_name = os.path.join(folder_path, 'y_test.csv')\n",
    "\n",
    "        X_train = pd.read_csv(train_x_name).to_numpy()\n",
    "        y_train = pd.read_csv(train_y_name).to_numpy().reshape(-1)\n",
    "        X_val = pd.read_csv(val_x_name).to_numpy()\n",
    "        y_val = pd.read_csv(val_y_name).to_numpy().reshape(-1)\n",
    "        X_test = pd.read_csv(test_x_name).to_numpy()\n",
    "        y_test = pd.read_csv(test_y_name).to_numpy().reshape(-1)\n",
    "\n",
    "        # expand the embeddings for the task\n",
    "        X_train = np.concatenate([X_train, np.round(np.tile(task_embeddings[task], (X_train.shape[0], 1)), 4)], axis=1)\n",
    "        X_val = np.concatenate([X_val,  np.round(np.tile(task_embeddings[task], (X_val.shape[0], 1)), 4)], axis=1)\n",
    "        X_test = np.concatenate([X_test, np.round(np.tile(task_embeddings[task], (X_test.shape[0], 1)), 4)], axis=1)\n",
    "\n",
    "        # class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        # class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "        X_train_all.append(X_train)\n",
    "        y_train_all.append(y_train)\n",
    "\n",
    "        X_val_all.append(X_val)\n",
    "        y_val_all.append(y_val)\n",
    "\n",
    "        pd.DataFrame(X_test).to_csv(os.path.join(folder_path_data, 'X_test.csv'), index=False)\n",
    "        pd.DataFrame(y_test).to_csv(os.path.join(folder_path_data, 'y_test.csv'), index=False)\n",
    "\n",
    "    X_train_all = np.concatenate(X_train_all, axis=0)\n",
    "    y_train_all = np.concatenate(y_train_all, axis=0)\n",
    "\n",
    "    X_val_all = np.concatenate(X_val_all, axis=0)\n",
    "    y_val_all = np.concatenate(y_val_all, axis=0)\n",
    "\n",
    "    pd.DataFrame(X_train_all).to_csv(f'multi_task_data_uq/{task_type}/X_train_all.csv', index=False)\n",
    "    pd.DataFrame(y_train_all).to_csv(f'multi_task_data_uq/{task_type}/y_train_all.csv', index=False)\n",
    "\n",
    "    pd.DataFrame(X_val_all).to_csv(f'multi_task_data_uq/{task_type}/X_val_all.csv', index=False)\n",
    "    pd.DataFrame(y_val_all).to_csv(f'multi_task_data_uq/{task_type}/y_val_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single_task_data/lab_hypoglycemia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.745 , -0.1219,  1.8125, ...,  0.2943,  0.6588,  0.7391],\n",
       "       [-2.037 , -0.47  ,  1.274 , ...,  0.2943,  0.6588,  0.7391],\n",
       "       [-1.877 , -1.647 ,  1.546 , ...,  0.2943,  0.6588,  0.7391],\n",
       "       ...,\n",
       "       [-1.975 , -1.2   , -0.7544, ...,  0.8698,  0.0425,  0.9779],\n",
       "       [-1.325 , -1.646 , -0.6934, ...,  0.8698,  0.0425,  0.9779],\n",
       "       [-1.88  , -0.7427, -0.2286, ...,  0.8698,  0.0425,  0.9779]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
