{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_row_entropy(df):\n",
    "    def entropy(row):\n",
    "        counts = row.value_counts(normalize=True)\n",
    "        # Calculate entropy\n",
    "        return -np.sum(counts * np.log2(counts)) + np.finfo(float).eps # np.finfo(float).eps prevents log(0)\n",
    "\n",
    "    # Apply the entropy function to each row\n",
    "    return df.apply(entropy, axis=1)\n",
    "\n",
    "def calculate_auc(y_true, y_scores):\n",
    "    return roc_auc_score(y_true, y_scores)\n",
    "\n",
    "\n",
    "def replace_yes_no(df):\n",
    "    \"\"\"\n",
    "    Replace items in the DataFrame:\n",
    "    - 'Yes' in the string gets replaced with 1\n",
    "    - 'No' in the string gets replaced with 0\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with modified values.\n",
    "    \"\"\"\n",
    "    def replace_value(item):\n",
    "        if isinstance(item, str):  # Only process string items\n",
    "            if 'Yes' in item:\n",
    "                return 1\n",
    "            elif 'No' in item:\n",
    "                return 0\n",
    "            elif 'no' in item:\n",
    "                return 0\n",
    "        return item  # Return the item unchanged if it is not a string or doesn't match 'Yes' or 'No'\n",
    "\n",
    "    return df.applymap(replace_value)\n",
    "\n",
    "def replace_yes_no_v2(df):\n",
    "    \"\"\"\n",
    "    Replace items in the DataFrame:\n",
    "    - 'Yes' in the string gets replaced with 1\n",
    "    - 'No' in the string gets replaced with 0\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with modified values.\n",
    "    \"\"\"\n",
    "    def replace_value(item):\n",
    "        if isinstance(item, str):  # Only process string items\n",
    "            if 'Yes' in item:\n",
    "                return 1\n",
    "            elif 'No' in item:\n",
    "                return 0\n",
    "            elif 'no' in item:\n",
    "                return 0\n",
    "        return item  # Return the item unchanged if it is not a string or doesn't match 'Yes' or 'No'\n",
    "\n",
    "    return df.applymap(replace_value)\n",
    "\n",
    "def evaluate_acc_uq(df_list):\n",
    "    for k in range(len(df_list)):\n",
    "        df_name = df_list[k]\n",
    "        df_pred = pd.read_csv(df_name)\n",
    "        gt_list = df_pred['gt']\n",
    "        df_pred_baseline = df_pred.loc[:, ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']]\n",
    "        print(df_name)\n",
    "        if df_name == 'results/gpt35/baseline/LOS_baseline.csv':\n",
    "            print(df_name)\n",
    "            df_pred_baseline = replace_yes_no_v2(df_pred_baseline)\n",
    "            df_pred_baseline.replace({'Yes': 0, 'No': 1, 'No, the patient will not be discharged within 7 days.':1}, inplace=True)\n",
    "        else:\n",
    "            df_pred_baseline = replace_yes_no(df_pred_baseline)\n",
    "            df_pred_baseline.replace({'Yes': 1, 'No': 0, 'No, the patient will not be readmitted in 30 days.':0, 'No.':0, \n",
    "                                    'No, based on the information provided, it is not possible to determine whether the patient will be transferred to the ICU on the same admission date.':0}, inplace=True)\n",
    "\n",
    "        uq_metric_baseline = calculate_row_entropy(df_pred_baseline).values\n",
    "        uq_metric_baseline = np.round(uq_metric_baseline, 10) + 0.0000000001\n",
    "\n",
    "\n",
    "        auc_list = []\n",
    "        acc_list = []\n",
    "        for c in df_pred_baseline.columns:\n",
    "            p = df_pred_baseline[c].values\n",
    "            auc = calculate_auc(df_pred['gt'].astype(int), df_pred_baseline[c])\n",
    "            acc = np.mean(df_pred['gt'].astype(int) == df_pred_baseline[c])\n",
    "            auc_list.append(auc)\n",
    "            acc_list.append(acc)\n",
    "        print(np.mean(acc_list).round(3), np.std(acc_list).round(3))\n",
    "        print(np.mean(auc_list).round(3), np.std(auc_list).round(3))\n",
    "\n",
    "        pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "        pred_list = ['pred_1']\n",
    "        uq_list = []\n",
    "        for p in pred_list: \n",
    "            uq_auc = calculate_auc(df_pred['gt'].astype(int) == df_pred_baseline[p].astype(int), uq_metric_baseline)\n",
    "            uq_list.append(uq_auc)\n",
    "            # print(uq_auc)\n",
    "        print(np.mean(uq_list).round(3), np.std(uq_list).round(3))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_single_uq(eval_dir, f, pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']):\n",
    "    df_gpt = pd.read_csv(os.path.join(eval_dir, f))\n",
    "    if 'Unnamed: 0' in df_gpt.columns:\n",
    "        df_gpt = df_gpt.drop(columns = ['Unnamed: 0'])\n",
    "    else:\n",
    "        pass\n",
    "    pred_0 = df_gpt.loc[:, pred_list]\n",
    "    pred_df = replace_yes_no_v2(pred_0)\n",
    "    pred_mat = pred_df.to_numpy()\n",
    "    \n",
    "    gt_list = df_gpt['gt'].values\n",
    "    pred_list = pred_mat.mean(axis = 1)\n",
    "    \n",
    "    whether_correct_or_not = np.array([(pred_mat[j] == gt_list[j]).mean() for j in range(len(gt_list))]) >= 0.5\n",
    "    entropy = calculate_row_entropy(pred_df).values\n",
    "    \n",
    "    uq_auc = calculate_auc(whether_correct_or_not, entropy)\n",
    "    auc = calculate_auc(gt_list, pred_list)\n",
    "    print(f\"Auc. score: {auc.round(4)}, Uncertainty Auc.: {uq_auc.round(4)}\")\n",
    "#     return uq_auc, auc\n",
    "    return auc, uq_auc\n",
    "\n",
    "def calculate_ensemble_uq(eval_dir1, eval_dir2, f1, f2, \n",
    "                          pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']):\n",
    "    df_gpt1 = pd.read_csv(os.path.join(eval_dir1, f))\n",
    "    df_gpt2 = pd.read_csv(os.path.join(eval_dir2, f))\n",
    "    \n",
    "    if 'Unnamed: 0' in df_gpt1.columns:\n",
    "        df_gpt1 = df_gpt1.drop(columns = ['Unnamed: 0'])\n",
    "    else:\n",
    "        pass\n",
    "    if 'Unnamed: 0' in df_gpt2.columns:\n",
    "        df_gpt2 = df_gpt2.drop(columns = ['Unnamed: 0'])\n",
    "    else:\n",
    "        pass\n",
    "    pred_1 = df_gpt1.loc[:, pred_list]\n",
    "    pred_2 = df_gpt2.loc[:, pred_list]\n",
    "    \n",
    "    pred_all = pd.concat([pred_1, pred_2], axis = 1)\n",
    "    pred_df = replace_yes_no_v2(pred_all)\n",
    "    pred_mat = pred_df.to_numpy()\n",
    "    gt_list_1 = df_gpt1['gt'].values\n",
    "    gt_list_2 = df_gpt2['gt'].values\n",
    "    \n",
    "    assert np.all(gt_list_1 == gt_list_2)\n",
    "    gt_list = gt_list_1\n",
    "    pred_list = pred_mat.mean(axis = 1)\n",
    "    \n",
    "    whether_correct_or_not = np.array([(pred_mat[j] == gt_list_1[j]).mean() for j in range(len(gt_list_1))]) >= 0.5\n",
    "    entropy = calculate_row_entropy(pred_df).values\n",
    "    \n",
    "    uq_auc = calculate_auc(whether_correct_or_not, entropy)\n",
    "    auc = calculate_auc(gt_list, pred_list)\n",
    "    print(f\"Auc. score: {auc.round(4)}, Uncertainty Auc.: {uq_auc.round(4)}\")\n",
    "#     return uq_auc, auc\n",
    "    return auc, uq_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list = ['results/gpt35/baseline/ICU_baseline.csv', 'results/gpt35/baseline/LOS_baseline.csv', 'results/gpt35/baseline/Readmin_baseline.csv']\n",
    "# # df_list = ['results/gpt35/cross_task/ICU_cross_task.csv', 'results/gpt35/cross_task/LOS_cross_task.csv', 'results/gpt35/cross_task/Readmin_cross_task.csv']\n",
    "\n",
    "\n",
    "# df_name = df_list[2]\n",
    "# df_pred = pd.read_csv(df_name)\n",
    "# gt_list = df_pred['gt']\n",
    "# df_pred_baseline = df_pred.loc[:, ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']]\n",
    "\n",
    "# if df_name == 'results/gpt35/baseline/LOS_baseline.csv':\n",
    "#     df_pred_baseline.replace({'Yes': 0, 'No': 1, 'No, the patient will not be discharged within 7 days.':1}, inplace=True)\n",
    "# else:\n",
    "#     df_pred_baseline.replace({'Yes': 1, 'No': 0, 'No, the patient will not be readmitted in 30 days.':0, 'No.':0, \n",
    "#                               'No, based on the information provided, it is not possible to determine whether the patient will be transferred to the ICU on the same admission date.':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/gpt4/baseline_new_diagnose_v2/value_new_hyperlipidemia.csv',\n",
       " 'results/gpt4/baseline_new_diagnose_v2/value_new_hypertension.csv',\n",
       " 'results/gpt4/baseline_new_diagnose_v2/value_new_acutemi.csv']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# eval_dir = \"results/gpt35/baseline/\"\n",
    "# eval_dir = \"results/gpt4/baseline/\"\n",
    "# eval_dir = 'results/gpt4/baseline_labtest/'\n",
    "# eval_dir = 'results/gpt4/cross_task_labtest/'\n",
    "# eval_dir = 'results/gpt35/baseline_labtest/'\n",
    "# eval_dir = 'results/gpt35/cross_task_labtest/'\n",
    "# eval_dir = \"results/gpt4_new/cross_task_labtest_reformulated/\"\n",
    "# eval_dir = \"results/gpt35_new/cross_task_labtest_reformulated/\"\n",
    "# eval_dir = \"results/gpt35_new/cross_task_general_operation_reformulated/\"\n",
    "# eval_dir = \"results/gpt4_new/cross_task_general_operation_reformulated/\"\n",
    "# eval_dir = \"results/gpt35/baseline_new_diagnose/\"\n",
    "# eval_dir = \"results/gpt4/baseline_new_diagnose/\"\n",
    "eval_dir = \"results/gpt4/baseline_new_diagnose_v2/\"\n",
    "# eval_dir = \"results/gpt35_new/cross_task_new_diagnose_reformulated/\"\n",
    "# eval_dir = \"results/gpt4_new/cross_task_new_diagnose_reformulated/\"\n",
    "\n",
    "# eval_dir = \"results/gpt35_new/cross_task_new_diagnose_blood_reformulated/\"\n",
    "# eval_dir = \"results/gpt4_new/cross_task_new_diagnose_blood_reformulated/\"\n",
    "\n",
    "# eval_dir = \"results/gpt4_new/cross_task_new_diagnose_blood_reformulated_v2/\"\n",
    "f = os.listdir(eval_dir)\n",
    "f_csv = [j for j in f if '.csv' in j]\n",
    "f_fullname_csv = [eval_dir + k for k in f_csv]\n",
    "f_fullname_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(eval_dir1), os.listdir(eval_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT3.5\n",
      "hyperlipidemia\n",
      "Auc. score: 0.5559, Uncertainty Auc.: 0.4203\n",
      "hypertension\n",
      "Auc. score: 0.4762, Uncertainty Auc.: 0.5238\n",
      "acutemi\n",
      "Auc. score: 0.5455, Uncertainty Auc.: 0.4545\n",
      "\n",
      "GPT 4\n",
      "hyperlipidemia\n",
      "Auc. score: 0.6289, Uncertainty Auc.: 0.4077\n",
      "hypertension\n",
      "Auc. score: 0.7136, Uncertainty Auc.: 0.4488\n",
      "acutemi\n",
      "Auc. score: 0.7317, Uncertainty Auc.: 0.3394\n",
      "\n",
      "GPT3.5-multi-task\n",
      "Acute Myocardial Infarction\n",
      "Auc. score: 0.4929, Uncertainty Auc.: 0.6379\n",
      "\n",
      "Hypertension\n",
      "Auc. score: 0.5758, Uncertainty Auc.: 0.4707\n",
      "\n",
      "Hyperlipidemia\n",
      "Auc. score: 0.5478, Uncertainty Auc.: 0.5032\n",
      "\n",
      "GPT4-multi-task\n",
      "Acute Myocardial Infarction\n",
      "Auc. score: 0.6149, Uncertainty Auc.: 0.3436\n",
      "Hypertension\n",
      "Auc. score: 0.7136, Uncertainty Auc.: 0.4222\n",
      "Hyperlipidemia\n",
      "Auc. score: 0.6845, Uncertainty Auc.: 0.4127\n",
      "\n",
      "Ensemble\n",
      "hyperlipidemia\n",
      "Auc. score: 0.6403, Uncertainty Auc.: 0.6053\n",
      "hypertension\n",
      "Auc. score: 0.692, Uncertainty Auc.: 0.5606\n",
      "acutemi\n",
      "Auc. score: 0.7109, Uncertainty Auc.: 0.4014\n",
      "\n",
      "Ensemble-multi-task\n",
      "Acute Myocardial Infarction\n",
      "Auc. score: 0.6074, Uncertainty Auc.: 0.7335\n",
      "Hypertension\n",
      "Auc. score: 0.7042, Uncertainty Auc.: 0.6804\n",
      "Hyperlipidemia\n",
      "Auc. score: 0.6736, Uncertainty Auc.: 0.7338\n"
     ]
    }
   ],
   "source": [
    "uq_list = []\n",
    "eval_dir1 = \"results/gpt35/baseline_new_diagnose_v2/\"\n",
    "eval_dir12 = 'results/gpt35/baseline_new_diagnose/'\n",
    "\n",
    "eval_dir2 = \"results/gpt4/baseline_new_diagnose_v2/\"\n",
    "eval_dir22 = \"results/gpt4/baseline_new_diagnose/\"\n",
    "\n",
    "eval_dir3 = \"results/gpt35_new/cross_task_new_diagnose_blood_reformulated/\"\n",
    "\n",
    "eval_dir4 = \"results/gpt4_new/cross_task_new_diagnose_blood_reformulated/\"\n",
    "\n",
    "pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "\n",
    "f_list_dir1 = os.listdir(eval_dir1)\n",
    "f_list_dir2 = os.listdir(eval_dir2)\n",
    "f_list_dir3 = os.listdir(eval_dir3)\n",
    "f_list_dir4 = os.listdir(eval_dir4)\n",
    "\n",
    "tab1 = []\n",
    "tab2 = []\n",
    "tab3 = []\n",
    "tab4 = []\n",
    "tab5 = []\n",
    "tab6 = []\n",
    "print('GPT3.5')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    a = calculate_single_uq(eval_dir1, f)\n",
    "    tab1.append(a)\n",
    "print('')\n",
    "print('GPT 4')\n",
    "for f in f_list_dir2:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    a = calculate_single_uq(eval_dir2, f)\n",
    "    tab2.append(a)\n",
    "    \n",
    "print('')\n",
    "print('GPT3.5-multi-task')\n",
    "for f in f_list:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    a = calculate_single_uq(eval_dir3, f)\n",
    "    tab3.append(a)\n",
    "    print('')\n",
    "print('GPT4-multi-task')\n",
    "for f in f_list:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    a = calculate_single_uq(eval_dir4, f)\n",
    "    tab4.append(a)\n",
    "print('')\n",
    "print('Ensemble')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir2\n",
    "    a = calculate_ensemble_uq(eval_dir1, eval_dir2, f, f)\n",
    "    tab5.append(a)\n",
    "print('')\n",
    "print('Ensemble-multi-task')\n",
    "for f in f_list_dir3:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir3\n",
    "    a = calculate_ensemble_uq(eval_dir3, eval_dir4, f, f)\n",
    "    tab6.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1 = pd.DataFrame(tab1).loc[[1, 0, 2]].round(4)\n",
    "tab2 = pd.DataFrame(tab2).loc[[1, 0, 2]].round(4)\n",
    "tab3 = pd.DataFrame(tab3).loc[[1, 2, 0]].round(4)\n",
    "tab4 = pd.DataFrame(tab4).loc[[1, 2, 0]].round(4)\n",
    "tab5 = pd.DataFrame(tab5).loc[[1, 2, 0]].round(4)\n",
    "tab6 = pd.DataFrame(tab6).loc[[1, 2, 0]].round(4)\n",
    "tab1 = tab1.reset_index(drop=True)\n",
    "tab2 = tab2.reset_index(drop=True)\n",
    "tab3 = tab3.reset_index(drop=True)\n",
    "tab4 = tab4.reset_index(drop=True)\n",
    "tab5 = tab5.reset_index(drop=True)\n",
    "tab6 = tab6.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_diag = pd.concat([tab1, tab3, tab2, tab4, tab5, tab6], axis = 1).round(4)\n",
    "df_new_diag = df_new_diag.reset_index(drop = True)\n",
    "# df_new_diag.to_csv('df_diag_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT3.5\n",
      "thrombocytopenia\n",
      "Auc. score: 0.5327, Uncertainty Auc.: 0.446\n",
      "anemia\n",
      "Auc. score: 0.4433, Uncertainty Auc.: 0.61\n",
      "hyperkalemia\n",
      "Auc. score: 0.4795, Uncertainty Auc.: 0.4821\n",
      "hyponatremia\n",
      "Auc. score: 0.4593, Uncertainty Auc.: 0.522\n",
      "hypoglycemia\n",
      "Auc. score: 0.5404, Uncertainty Auc.: 0.441\n",
      "\n",
      "GPT 4\n",
      "thrombocytopenia\n",
      "Auc. score: 0.2917, Uncertainty Auc.: 0.5548\n",
      "anemia\n",
      "Auc. score: 0.1962, Uncertainty Auc.: 0.6877\n",
      "hyperkalemia\n",
      "Auc. score: 0.2508, Uncertainty Auc.: 0.5094\n",
      "hyponatremia\n",
      "Auc. score: 0.2652, Uncertainty Auc.: 0.5347\n",
      "hypoglycemia\n",
      "Auc. score: 0.7131, Uncertainty Auc.: 0.4388\n",
      "\n",
      "GPT3.5-multi-task\n",
      "thrombocytopenia\n",
      "Auc. score: 0.3745, Uncertainty Auc.: 0.5464\n",
      "anemia\n",
      "Auc. score: 0.2739, Uncertainty Auc.: 0.7254\n",
      "hyperkalemia\n",
      "Auc. score: 0.3673, Uncertainty Auc.: 0.5988\n",
      "hyponatremia\n",
      "Auc. score: 0.3189, Uncertainty Auc.: 0.6303\n",
      "hypoglycemia\n",
      "Auc. score: 0.5416, Uncertainty Auc.: 0.4352\n",
      "\n",
      "GPT4-multi-task\n",
      "thrombocytopenia\n",
      "Auc. score: 0.2062, Uncertainty Auc.: 0.5246\n",
      "anemia\n",
      "Auc. score: 0.2173, Uncertainty Auc.: 0.6044\n",
      "hyperkalemia\n",
      "Auc. score: 0.402, Uncertainty Auc.: 0.5125\n",
      "hyponatremia\n",
      "Auc. score: 0.2844, Uncertainty Auc.: 0.4939\n",
      "hypoglycemia\n",
      "Auc. score: 0.6688, Uncertainty Auc.: 0.4481\n",
      "\n",
      "Ensemble\n",
      "thrombocytopenia\n",
      "Auc. score: 0.3235, Uncertainty Auc.: 0.6382\n",
      "anemia\n",
      "Auc. score: 0.2037, Uncertainty Auc.: 0.7722\n",
      "hyperkalemia\n",
      "Auc. score: 0.2553, Uncertainty Auc.: 0.847\n",
      "hyponatremia\n",
      "Auc. score: 0.2745, Uncertainty Auc.: 0.6186\n",
      "hypoglycemia\n",
      "Auc. score: 0.7052, Uncertainty Auc.: 0.5274\n",
      "\n",
      "Ensemble-multi-task\n",
      "thrombocytopenia\n",
      "Auc. score: 0.2973, Uncertainty Auc.: 0.5594\n",
      "anemia\n",
      "Auc. score: 0.2069, Uncertainty Auc.: 0.6825\n",
      "hyperkalemia\n",
      "Auc. score: 0.3446, Uncertainty Auc.: 0.5948\n",
      "hyponatremia\n",
      "Auc. score: 0.2437, Uncertainty Auc.: 0.6786\n",
      "hypoglycemia\n",
      "Auc. score: 0.6386, Uncertainty Auc.: 0.5723\n"
     ]
    }
   ],
   "source": [
    "uq_list = []\n",
    "eval_dir1 = \"results/gpt35/baseline_labtest_v2/\"\n",
    "eval_dir2 = \"results/gpt4/baseline_labtest_v2/\"\n",
    "eval_dir3 = \"results/gpt35_new/cross_task_labtest_reformulated/\"\n",
    "eval_dir4 = \"results/gpt4_new/cross_task_labtest_reformulated/\"\n",
    "\n",
    "pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "\n",
    "f_list_dir1 = os.listdir(eval_dir1)\n",
    "f_list_dir2 = os.listdir(eval_dir2)\n",
    "f_list_dir3 = os.listdir(eval_dir3)\n",
    "f_list_dir4 = os.listdir(eval_dir4)\n",
    "\n",
    "tab1 = []\n",
    "tab2 = []\n",
    "tab3 = []\n",
    "tab4 = []\n",
    "tab5 = []\n",
    "tab6 = []\n",
    "\n",
    "print('GPT3.5')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir2\n",
    "    a = calculate_single_uq(eval_dir1, f)\n",
    "    tab1.append(a)\n",
    "print('')\n",
    "print('GPT 4')\n",
    "for f in f_list_dir2:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir1\n",
    "    a = calculate_single_uq(eval_dir2, f)\n",
    "    tab2.append(a)\n",
    "print(\"\")\n",
    "print('GPT3.5-multi-task')\n",
    "for f in f_list_dir3:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "#     assert f in f_list_dir4\n",
    "    a = calculate_single_uq(eval_dir3, f)\n",
    "    tab3.append(a)\n",
    "print(\"\")\n",
    "print('GPT4-multi-task')\n",
    "for f in f_list_dir4:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "#     assert f in f_list_dir4\n",
    "    a = calculate_single_uq(eval_dir4, f)\n",
    "    tab4.append(a)\n",
    "print('')\n",
    "print('Ensemble')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "#     assert f in f_list_dir2\n",
    "    a = calculate_ensemble_uq(eval_dir1, eval_dir2, f, f)\n",
    "    tab5.append(a)\n",
    "print('')\n",
    "print('Ensemble-multi-task')\n",
    "for f in f_list_dir3:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "#     assert f in f_list_dir2\n",
    "    a = calculate_ensemble_uq(eval_dir3, eval_dir4, f, f)\n",
    "    tab6.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1 = pd.DataFrame(tab1).loc[[0, 2, 4, 3, 1]].round(4)\n",
    "tab2 = pd.DataFrame(tab2).loc[[0, 2, 4, 3, 1]].round(4)\n",
    "tab3 = pd.DataFrame(tab3).loc[[0, 2, 4, 3, 1]].round(4)\n",
    "tab4 = pd.DataFrame(tab4).loc[[0, 2, 4, 3, 1]].round(4)\n",
    "tab5 = pd.DataFrame(tab5).loc[[0, 2, 4, 3, 1]].round(4)\n",
    "tab6 = pd.DataFrame(tab6).loc[[0, 2, 4, 3, 1]].round(4)\n",
    "\n",
    "tab1 = tab1.reset_index(drop=True)\n",
    "tab2 = tab2.reset_index(drop=True)\n",
    "tab3 = tab3.reset_index(drop=True)\n",
    "tab4 = tab4.reset_index(drop=True)\n",
    "tab5 = tab5.reset_index(drop=True)\n",
    "tab6 = tab6.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = pd.concat([tab1, tab3, tab2, tab4, tab5, tab6], axis = 1).round(4)\n",
    "df_lab = df_lab.reset_index(drop = True)\n",
    "df_lab.to_csv('df_lab_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT3.5\n",
      "ICU\n",
      "Auc. score: 0.5047, Uncertainty Auc.: 0.5331\n",
      "Readmin\n",
      "Auc. score: 0.5408, Uncertainty Auc.: 0.4592\n",
      "LOS\n",
      "Auc. score: 0.543, Uncertainty Auc.: 0.457\n",
      "\n",
      "GPT 4\n",
      "ICU\n",
      "Auc. score: 0.5938, Uncertainty Auc.: 0.514\n",
      "Readmin\n",
      "Auc. score: 0.5024, Uncertainty Auc.: 0.4967\n",
      "LOS\n",
      "Auc. score: 0.3614, Uncertainty Auc.: 0.4992\n",
      "\n",
      "GPT3.5-multi-task\n",
      "ICU transfer\n",
      "Auc. score: 0.6853, Uncertainty Auc.: 0.3596\n",
      "Long length of stay\n",
      "Auc. score: 0.6153, Uncertainty Auc.: 0.4265\n",
      "Readmission\n",
      "Auc. score: 0.4327, Uncertainty Auc.: 0.4633\n",
      "\n",
      "GPT4-multi-task\n",
      "ICU transfer\n",
      "Auc. score: 0.7083, Uncertainty Auc.: 0.4888\n",
      "Long length of stay\n",
      "Auc. score: 0.5125, Uncertainty Auc.: 0.4875\n",
      "Readmission\n",
      "Auc. score: 0.536, Uncertainty Auc.: 0.6566\n",
      "\n",
      "Ensemble\n",
      "ICU\n",
      "Auc. score: 0.5538, Uncertainty Auc.: 0.6455\n",
      "Readmin\n",
      "Auc. score: 0.5461, Uncertainty Auc.: 0.8385\n",
      "LOS\n",
      "Auc. score: 0.4126, Uncertainty Auc.: 0.5671\n",
      "\n",
      "Ensemble-multi-task\n",
      "ICU transfer\n",
      "Auc. score: 0.7552, Uncertainty Auc.: 0.4831\n",
      "Long length of stay\n",
      "Auc. score: 0.6166, Uncertainty Auc.: 0.7237\n",
      "Readmission\n",
      "Auc. score: 0.4728, Uncertainty Auc.: 0.8501\n"
     ]
    }
   ],
   "source": [
    "uq_list = []\n",
    "eval_dir1 = \"results/gpt35/baseline_general_operation/\"\n",
    "eval_dir2 = \"results/gpt4/baseline_general_operation/\"\n",
    "eval_dir3 = \"results/gpt35_new/cross_task_general_operation_reformulated/\"\n",
    "eval_dir4 = \"results/gpt4_new//cross_task_general_operation_reformulated/\"\n",
    "\n",
    "pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "\n",
    "tab1 = []\n",
    "tab2 = []\n",
    "tab3 = []\n",
    "tab4 = []\n",
    "tab5 = []\n",
    "tab6 = []\n",
    "\n",
    "f_list_dir1 = os.listdir(eval_dir1)\n",
    "f_list_dir2 = os.listdir(eval_dir2)\n",
    "f_list_dir3 = os.listdir(eval_dir3)\n",
    "f_list_dir4 = os.listdir(eval_dir4)\n",
    "\n",
    "print('GPT3.5')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[0].split('.csv')[0])\n",
    "    assert f in f_list_dir2\n",
    "    a = calculate_single_uq(eval_dir1, f)\n",
    "    tab1.append(a)\n",
    "print('')\n",
    "print('GPT 4')\n",
    "for f in f_list_dir2:\n",
    "    print(f.split('_')[0].split('.csv')[0])\n",
    "    assert f in f_list_dir1\n",
    "    a = calculate_single_uq(eval_dir2, f)\n",
    "    tab2.append(a)\n",
    "print('')\n",
    "print('GPT3.5-multi-task')\n",
    "for f in f_list_dir3:\n",
    "    print(f.split('_')[0].split('.csv')[0])\n",
    "#     assert f in f_list_dir1\n",
    "    a = calculate_single_uq(eval_dir3, f)\n",
    "    tab3.append(a)\n",
    "print('')\n",
    "print('GPT4-multi-task')\n",
    "for f in f_list_dir4:\n",
    "    print(f.split('_')[0].split('.csv')[0])\n",
    "#     assert f in f_list_dir1\n",
    "    a = calculate_single_uq(eval_dir4, f)\n",
    "    tab4.append(a)\n",
    "print('')\n",
    "print('Ensemble')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[0].split('.csv')[0])\n",
    "    assert f in f_list_dir2\n",
    "    a = calculate_ensemble_uq(eval_dir1, eval_dir2, f, f)\n",
    "    tab5.append(a)\n",
    "print('')\n",
    "print('Ensemble-multi-task')\n",
    "for f in f_list_dir3:\n",
    "    print(f.split('_')[0].split('.csv')[0])\n",
    "#     assert f in f_list_dir\n",
    "    a = calculate_ensemble_uq(eval_dir3, eval_dir4, f, f)\n",
    "    tab6.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.616562</td>\n",
       "      <td>0.723684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.755208</td>\n",
       "      <td>0.483073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472826</td>\n",
       "      <td>0.850055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "1  0.616562  0.723684\n",
       "0  0.755208  0.483073\n",
       "2  0.472826  0.850055"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tab6).loc[[1, 0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1 = pd.DataFrame(tab1).loc[[2, 0, 1]].round(4)\n",
    "tab2 = pd.DataFrame(tab2).loc[[2, 0, 1]].round(4)\n",
    "tab3 = pd.DataFrame(tab3).loc[[1, 0, 2]].round(4)\n",
    "tab4 = pd.DataFrame(tab4).loc[[1, 0, 2]].round(4)\n",
    "tab5 = pd.DataFrame(tab5).loc[[1, 0, 2]].round(4)\n",
    "tab6 = pd.DataFrame(tab6).loc[[1, 0, 2]].round(4)\n",
    "df_general = pd.concat([tab1, tab3, tab2, tab4, tab5, tab6], axis = 1).round(4)\n",
    "df_general = df_general.reset_index(drop = True)\n",
    "df_general.to_csv('df_general_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5430</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.3614</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>0.4126</td>\n",
       "      <td>0.5671</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.8501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.5938</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>0.6455</td>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.4831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.6153</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>0.6166</td>\n",
       "      <td>0.7237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       0       1       0       1       0       1       0   \n",
       "0  0.5430  0.4570  0.4327  0.4633  0.3614  0.4992  0.5360  0.6566  0.4126  \\\n",
       "1  0.5047  0.5331  0.6853  0.3596  0.5938  0.5140  0.7083  0.4888  0.5538   \n",
       "2  0.5408  0.4592  0.6153  0.4265  0.5024  0.4967  0.5125  0.4875  0.5461   \n",
       "\n",
       "        1       0       1  \n",
       "0  0.5671  0.4728  0.8501  \n",
       "1  0.6455  0.7552  0.4831  \n",
       "2  0.8385  0.6166  0.7237  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT3.5\n",
      "hyperlipidemia\n",
      "Auc. score: 0.6076, Uncertainty Auc.: 0.3924\n",
      "hypertension\n",
      "Auc. score: 0.4594, Uncertainty Auc.: 0.5406\n",
      "acutemi\n",
      "Auc. score: 0.5208, Uncertainty Auc.: 0.4792\n",
      "\n",
      "GPT 4\n",
      "hyperlipidemia\n",
      "Auc. score: 0.6367, Uncertainty Auc.: 0.4407\n",
      "hypertension\n",
      "Auc. score: 0.693, Uncertainty Auc.: 0.4821\n",
      "acutemi\n",
      "Auc. score: 0.7356, Uncertainty Auc.: 0.3602\n",
      "\n",
      "Ensemble\n",
      "hyperlipidemia\n",
      "Auc. score: 0.6403, Uncertainty Auc.: 0.6053\n",
      "hypertension\n",
      "Auc. score: 0.692, Uncertainty Auc.: 0.5606\n",
      "acutemi\n",
      "Auc. score: 0.7109, Uncertainty Auc.: 0.4014\n"
     ]
    }
   ],
   "source": [
    "uq_list = []\n",
    "eval_dir1 = \"results/gpt35/baseline_new_diagnose_v2/\"\n",
    "eval_dir12 = 'results/gpt35/baseline_new_diagnose_v1/'\n",
    "\n",
    "eval_dir2 = \"results/gpt4/baseline_new_diagnose_v2/\"\n",
    "eval_dir22 = \"results/gpt4/baseline_new_diagnose_v1/\"\n",
    "\n",
    "pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "\n",
    "f_list_dir1 = os.listdir(eval_dir1)\n",
    "f_list_dir2 = os.listdir(eval_dir2)\n",
    "\n",
    "print('GPT3.5')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir2\n",
    "    calculate_ensemble_uq(eval_dir1, eval_dir12, f, f)\n",
    "print('')\n",
    "print('GPT 4')\n",
    "for f in f_list_dir2:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir1\n",
    "    calculate_ensemble_uq(eval_dir2, eval_dir22, f, f)\n",
    "\n",
    "print('')\n",
    "print('Ensemble')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir2\n",
    "    calculate_ensemble_uq(eval_dir1, eval_dir2, f, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT3.5\n",
      "hyperlipidemia\n",
      "Auc. score: 0.6076, Uncertainty Auc.: 0.3924\n",
      "hypertension\n",
      "Auc. score: 0.4594, Uncertainty Auc.: 0.5406\n",
      "acutemi\n",
      "Auc. score: 0.5208, Uncertainty Auc.: 0.4792\n",
      "\n",
      "GPT 4\n",
      "hyperlipidemia\n",
      "Auc. score: 0.6367, Uncertainty Auc.: 0.4407\n",
      "hypertension\n",
      "Auc. score: 0.693, Uncertainty Auc.: 0.4821\n",
      "acutemi\n",
      "Auc. score: 0.7356, Uncertainty Auc.: 0.3602\n",
      "\n",
      "Ensemble\n",
      "hyperlipidemia\n",
      "Auc. score: 0.6403, Uncertainty Auc.: 0.6053\n",
      "hypertension\n",
      "Auc. score: 0.692, Uncertainty Auc.: 0.5606\n",
      "acutemi\n",
      "Auc. score: 0.7109, Uncertainty Auc.: 0.4014\n"
     ]
    }
   ],
   "source": [
    "eval_dir1 = \"results/gpt35/baseline_new_diagnose_v2/\"\n",
    "eval_dir12 = 'results/gpt35/baseline_new_diagnose_v1/'\n",
    "\n",
    "eval_dir2 = \"results/gpt4/baseline_new_diagnose_v2/\"\n",
    "eval_dir22 = \"results/gpt4/baseline_new_diagnose_v1/\"\n",
    "\n",
    "pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "\n",
    "f_list_dir1 = os.listdir(eval_dir1)\n",
    "f_list_dir2 = os.listdir(eval_dir2)\n",
    "\n",
    "print('GPT3.5')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir2\n",
    "    calculate_ensemble_uq(eval_dir1, eval_dir12, f, f)\n",
    "print('')\n",
    "print('GPT 4')\n",
    "for f in f_list_dir2:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir1\n",
    "    calculate_ensemble_uq(eval_dir2, eval_dir22, f, f)\n",
    "\n",
    "print('')\n",
    "print('Ensemble')\n",
    "for f in f_list_dir1:\n",
    "    print(f.split('_')[-1].split('.csv')[0])\n",
    "    assert f in f_list_dir2\n",
    "    calculate_ensemble_uq(eval_dir1, eval_dir2, f, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7108753315649868"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_auc(gt_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_1  pred_2  pred_3  pred_4  pred_5  pred_1  pred_2  pred_3  pred_4   \n",
       "0        0       0       1       0       0       1       0       1       0  \\\n",
       "1        0       0       0       0       0       0       0       0       0   \n",
       "2        0       0       0       0       0       0       0       0       0   \n",
       "3        0       1       0       0       0       0       0       0       0   \n",
       "4        1       0       0       0       0       1       1       1       1   \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "95       0       0       0       0       0       0       0       0       0   \n",
       "96       0       0       0       0       0       0       0       0       0   \n",
       "97       0       0       0       0       0       0       0       0       0   \n",
       "98       0       0       0       0       0       0       0       0       0   \n",
       "99       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    pred_5  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  \n",
       "..     ...  \n",
       "95       0  \n",
       "96       0  \n",
       "97       0  \n",
       "98       0  \n",
       "99       0  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = f_fullname_csv[0]\n",
    "df_pred = pd.read_csv(df_name)\n",
    "gt_list = df_pred['gt']\n",
    "df_pred_baseline = df_pred.loc[:, ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_1 pred_2 pred_3 pred_4 pred_5\n",
       "0     Yes    Yes     No    Yes    Yes\n",
       "1      No     No     No     No     No\n",
       "2      No    Yes     No     No    Yes\n",
       "3     Yes    Yes    Yes    Yes    Yes\n",
       "4     Yes    Yes    Yes    Yes    Yes\n",
       "..    ...    ...    ...    ...    ...\n",
       "95     No     No     No     No     No\n",
       "96     No     No     No     No     No\n",
       "97     No     No     No     No     No\n",
       "98     No     No     No     No     No\n",
       "99     No     No     No     No     No\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/gpt35/baseline_new_diagnose/new_celiac.csv',\n",
       " 'results/gpt35/baseline_new_diagnose/new_acutemi.csv',\n",
       " 'results/gpt35/baseline_new_diagnose/new_lupus.csv',\n",
       " 'results/gpt35/baseline_new_diagnose/new_pancan.csv',\n",
       " 'results/gpt35/baseline_new_diagnose/new_hypertension.csv',\n",
       " 'results/gpt35/baseline_new_diagnose/new_hyperlipidemia.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dir1 = \"results/gpt4/baseline_new_diagnose/\"\n",
    "\n",
    "eval_dir2 = \"results/gpt35/baseline_new_diagnose/\"\n",
    "\n",
    "f1 = os.listdir(eval_dir1)\n",
    "f_csv1 = [j for j in f1 if '.csv' in j]\n",
    "f_fullname_csv1 = [eval_dir1 + k for k in f_csv1]\n",
    "\n",
    "f2 = os.listdir(eval_dir1)\n",
    "f_csv2 = [j for j in f2 if '.csv' in j]\n",
    "f_fullname_csv2 = [eval_dir2 + k for k in f_csv2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/gpt4/baseline_new_diagnose_v2/value_new_hypertension.csv\n",
      "0.594 0.022\n",
      "0.664 0.024\n",
      "0.43 0.0\n",
      "\n",
      "results/gpt4/baseline_new_diagnose_v2/value_new_acutemi.csv\n",
      "0.7 0.023\n",
      "0.664 0.034\n",
      "0.432 0.0\n",
      "\n",
      "results/gpt4/baseline_new_diagnose_v2/value_new_hyperlipidemia.csv\n",
      "0.62 0.011\n",
      "0.594 0.011\n",
      "0.432 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/lkqtqczs0sd9pbv2jxn6d_h80000gn/T/ipykernel_60460/2473183500.py:37: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(replace_value)\n",
      "/var/folders/ms/lkqtqczs0sd9pbv2jxn6d_h80000gn/T/ipykernel_60460/2473183500.py:37: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(replace_value)\n",
      "/var/folders/ms/lkqtqczs0sd9pbv2jxn6d_h80000gn/T/ipykernel_60460/2473183500.py:37: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(replace_value)\n"
     ]
    }
   ],
   "source": [
    "# print('gpt3.5 baseline')\n",
    "# evaluate_acc_uq(df_list= ['results/gpt35/baseline/ICU_baseline.csv', 'results/gpt35/baseline/LOS_baseline.csv', 'results/gpt35/baseline/Readmin_baseline.csv'])\n",
    "# print('gpt3.5 cross task')\n",
    "# evaluate_acc_uq(df_list= ['results/gpt35/cross_task/ICU_cross_task.csv', 'results/gpt35/cross_task/LOS_cross_task.csv', 'results/gpt35/cross_task/Readmin_cross_task.csv'])\n",
    "\n",
    "# evaluate_acc_uq(df_list= ['results/gpt35/baseline2/ICU_baseline.csv', 'results/gpt35/baseline2/LOS_baseline.csv', 'results/gpt35/baseline/Readmin_baseline.csv'])\n",
    "evaluate_acc_uq(f_fullname_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('gpt3.5 baseline')\n",
    "evaluate_acc_uq(df_list= ['results/gpt35/baseline/ICU_baseline.csv', 'results/gpt35/baseline/LOS_baseline.csv', 'results/gpt35/baseline/Readmin_baseline.csv'])\n",
    "\n",
    "evaluate_acc_uq(df_list= ['results/gpt35/cross_task/ICU_cross_task.csv', 'results/gpt35/cross_task/LOS_cross_task.csv', 'results/gpt35/cross_task/Readmin_cross_task.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58 0.06196773353931864\n",
      "0.49749999999999994 0.054857770643729216\n",
      "0.60125 0.0\n",
      "\n",
      "0.6759999999999999 0.030724582991474406\n",
      "0.5129499766245909 0.03369290952600669\n",
      "0.5752380952380952 0.0\n",
      "\n",
      "0.688 0.029257477676655565\n",
      "0.49674599320058277 0.033386100704494735\n",
      "0.5857843137254902 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list = ['results/gpt35/cross_task/ICU_cross_task.csv', 'results/gpt35/cross_task/LOS_cross_task.csv', 'results/gpt35/cross_task/Readmin_cross_task.csv']\n",
    "for k in range(3):\n",
    "    df_name = df_list[k]\n",
    "    df_pred = pd.read_csv(df_name)\n",
    "    gt_list = df_pred['gt']\n",
    "    df_pred_baseline = df_pred.loc[:, ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']]\n",
    "\n",
    "    if df_name == 'results/gpt35/baseline/LOS_baseline.csv':\n",
    "        df_pred_baseline.replace({'Yes': 0, 'No': 1, 'No, the patient will not be discharged within 7 days.':1}, inplace=True)\n",
    "    else:\n",
    "        df_pred_baseline.replace({'Yes': 1, 'No': 0, 'No, the patient will not be readmitted in 30 days.':0, 'No.':0, \n",
    "                                'No, based on the information provided, it is not possible to determine whether the patient will be transferred to the ICU on the same admission date.':0}, inplace=True)\n",
    "\n",
    "    uq_metric_baseline = calculate_row_entropy(df_pred_baseline).values\n",
    "    uq_metric_baseline = np.round(uq_metric_baseline, 10) + 0.0000000001\n",
    "\n",
    "\n",
    "    auc_list = []\n",
    "    acc_list = []\n",
    "    for c in df_pred_baseline.columns:\n",
    "        p = df_pred_baseline[c].values\n",
    "        auc = calculate_auc(df_pred['gt'].astype(int), df_pred_baseline[c])\n",
    "        acc = np.mean(df_pred['gt'].astype(int) == df_pred_baseline[c])\n",
    "        auc_list.append(auc)\n",
    "        acc_list.append(acc)\n",
    "    print(np.mean(acc_list), np.std(acc_list))\n",
    "    print(np.mean(auc_list), np.std(auc_list))\n",
    "\n",
    "    pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "    pred_list = ['pred_5']\n",
    "    uq_list = []\n",
    "    for p in pred_list: \n",
    "        uq_auc = calculate_auc(df_pred['gt'].astype(int) == df_pred_baseline[p].astype(int), uq_metric_baseline)\n",
    "        uq_list.append(uq_auc)\n",
    "        # print(uq_auc)\n",
    "    print(np.mean(uq_list), np.std(uq_list))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41800000000000004 0.04621688003316537\n",
      "0.50125 0.06304760106459247\n",
      "0.41339396444811904 0.0\n",
      "\n",
      "0.31799999999999995 0.019390719429665314\n",
      "0.4898083216456288 0.023819346854945612\n",
      "0.49805730937348225 0.0\n",
      "\n",
      "0.698 0.024819347291981687\n",
      "0.5099077221952404 0.025904797942854055\n",
      "0.5040588533739219 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list = ['results/gpt35/baseline/ICU_baseline.csv', 'results/gpt35/baseline/LOS_baseline.csv', 'results/gpt35/baseline/Readmin_baseline.csv']\n",
    "\n",
    "for k in range(3):\n",
    "    df_name = df_list[k]\n",
    "    df_pred = pd.read_csv(df_name)\n",
    "    gt_list = df_pred['gt']\n",
    "    df_pred_baseline = df_pred.loc[:, ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']]\n",
    "\n",
    "    if df_name == 'results/gpt35/baseline/LOS_baseline.csv':\n",
    "        df_pred_baseline.replace({'Yes': 0, 'No': 1, 'No, the patient will not be discharged within 7 days.':1}, inplace=True)\n",
    "    else:\n",
    "        df_pred_baseline.replace({'Yes': 1, 'No': 0, 'No, the patient will not be readmitted in 30 days.':0, 'No.':0, \n",
    "                                'No, based on the information provided, it is not possible to determine whether the patient will be transferred to the ICU on the same admission date.':0}, inplace=True)\n",
    "\n",
    "    uq_metric_baseline = calculate_row_entropy(df_pred_baseline).values\n",
    "    uq_metric_baseline = np.round(uq_metric_baseline, 10) + 0.0000000001\n",
    "\n",
    "\n",
    "    auc_list = []\n",
    "    acc_list = []\n",
    "    for c in df_pred_baseline.columns:\n",
    "        p = df_pred_baseline[c].values\n",
    "        auc = calculate_auc(df_pred['gt'].astype(int), df_pred_baseline[c])\n",
    "        acc = np.mean(df_pred['gt'].astype(int) == df_pred_baseline[c])\n",
    "        auc_list.append(auc)\n",
    "        acc_list.append(acc)\n",
    "    print(np.mean(acc_list), np.std(acc_list))\n",
    "    print(np.mean(auc_list), np.std(auc_list))\n",
    "\n",
    "    pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "    pred_list = ['pred_5']\n",
    "    uq_list = []\n",
    "    for p in pred_list: \n",
    "        uq_auc = calculate_auc(df_pred['gt'].astype(int) == df_pred_baseline[p].astype(int), uq_metric_baseline)\n",
    "        uq_list.append(uq_auc)\n",
    "        # print(uq_auc)\n",
    "    print(np.mean(uq_list), np.std(uq_list))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306 0.01200000000000001\n",
      "0.5662499999999999 0.007499999999999973\n",
      "0.44370404411764697 0.0\n",
      "\n",
      "0.5479999999999999 0.018330302779823324\n",
      "0.40598410472183255 0.02124483926448054\n",
      "0.4869441044471644 0.0\n",
      "\n",
      "0.35200000000000004 0.019390719429665308\n",
      "0.5069451189898009 0.014140165686196084\n",
      "0.5420496323529412 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list = ['results/gpt4/baseline/ICU_baseline.csv', 'results/gpt4/baseline/LOS_baseline.csv', 'results/gpt4/baseline/Readmin_baseline.csv']\n",
    "for k in range(3):\n",
    "    df_name = df_list[k]\n",
    "    df_pred = pd.read_csv(df_name)\n",
    "    gt_list = df_pred['gt']\n",
    "    df_pred_baseline = df_pred.loc[:, ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']]\n",
    "\n",
    "    if df_name == 'results/gpt35/baseline/LOS_baseline.csv':\n",
    "        df_pred_baseline.replace({'Yes': 0, 'No': 1, 'No, the patient will not be discharged within 7 days.':1}, inplace=True)\n",
    "    else:\n",
    "        df_pred_baseline.replace({'Yes': 1, 'No': 0, 'No, the patient will not be readmitted in 30 days.':0, 'No.':0, \n",
    "                                'No, based on the information provided, it is not possible to determine whether the patient will be transferred to the ICU on the same admission date.':0}, inplace=True)\n",
    "\n",
    "    uq_metric_baseline = calculate_row_entropy(df_pred_baseline).values\n",
    "    uq_metric_baseline = np.round(uq_metric_baseline, 10) + 0.0000000001\n",
    "\n",
    "\n",
    "    auc_list = []\n",
    "    acc_list = []\n",
    "    for c in df_pred_baseline.columns:\n",
    "        p = df_pred_baseline[c].values\n",
    "        auc = calculate_auc(df_pred['gt'].astype(int), df_pred_baseline[c])\n",
    "        acc = np.mean(df_pred['gt'].astype(int) == df_pred_baseline[c])\n",
    "        auc_list.append(auc)\n",
    "        acc_list.append(acc)\n",
    "    print(np.mean(acc_list), np.std(acc_list))\n",
    "    print(np.mean(auc_list), np.std(auc_list))\n",
    "\n",
    "    pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "    pred_list = ['pred_5']\n",
    "    uq_list = []\n",
    "    for p in pred_list: \n",
    "        uq_auc = calculate_auc(df_pred['gt'].astype(int) == df_pred_baseline[p].astype(int), uq_metric_baseline)\n",
    "        uq_list.append(uq_auc)\n",
    "        # print(uq_auc)\n",
    "    print(np.mean(uq_list), np.std(uq_list))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.404 0.022449944320643647\n",
      "0.5225 0.01837117307087385\n",
      "0.4800509337860781 0.0\n",
      "\n",
      "0.434 0.0349857113690718\n",
      "0.37489481065918656 0.03466042724909326\n",
      "0.5341050020669699 0.0\n",
      "\n",
      "0.36200000000000004 0.028565713714171402\n",
      "0.47115104419621173 0.03137249883769452\n",
      "0.6530135823429541 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/lkqtqczs0sd9pbv2jxn6d_h80000gn/T/ipykernel_59422/2079649520.py:35: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(replace_value)\n",
      "/var/folders/ms/lkqtqczs0sd9pbv2jxn6d_h80000gn/T/ipykernel_59422/2079649520.py:35: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(replace_value)\n",
      "/var/folders/ms/lkqtqczs0sd9pbv2jxn6d_h80000gn/T/ipykernel_59422/2079649520.py:35: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(replace_value)\n"
     ]
    }
   ],
   "source": [
    "df_list = ['results/gpt4/cross_task/ICU_cross_task.csv', 'results/gpt4/cross_task/LOS_cross_task.csv', 'results/gpt4/cross_task/Readmin_cross_task.csv']\n",
    "for k in range(3):\n",
    "    df_name = df_list[k]\n",
    "    df_pred = pd.read_csv(df_name)\n",
    "    gt_list = df_pred['gt']\n",
    "    df_pred_baseline = df_pred.loc[:, ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']]\n",
    "\n",
    "    if df_name == 'results/gpt35/baseline/LOS_baseline.csv':\n",
    "        df_pred_baseline = replace_yes_no_v2(df_pred_baseline)\n",
    "        df_pred_baseline.replace({'Yes': 0, 'No': 1, 'No, the patient will not be discharged within 7 days.':1}, inplace=True)\n",
    "        \n",
    "    else:\n",
    "        df_pred_baseline = replace_yes_no(df_pred_baseline)\n",
    "        df_pred_baseline.replace({'Yes': 1, 'No': 0, 'No, the patient will not be readmitted in 30 days.':0, 'No.':0, \n",
    "                                'No, based on the information provided, it is not possible to determine whether the patient will be transferred to the ICU on the same admission date.':0}, inplace=True)\n",
    "\n",
    "    uq_metric_baseline = calculate_row_entropy(df_pred_baseline).values\n",
    "    uq_metric_baseline = np.round(uq_metric_baseline, 10) + 0.0000000001\n",
    "\n",
    "\n",
    "    auc_list = []\n",
    "    acc_list = []\n",
    "    for c in df_pred_baseline.columns:\n",
    "        p = df_pred_baseline[c].values\n",
    "        auc = calculate_auc(df_pred['gt'].astype(int), df_pred_baseline[c])\n",
    "        acc = np.mean(df_pred['gt'].astype(int) == df_pred_baseline[c])\n",
    "        auc_list.append(auc)\n",
    "        acc_list.append(acc)\n",
    "    print(np.mean(acc_list), np.std(acc_list))\n",
    "    print(np.mean(auc_list), np.std(auc_list))\n",
    "\n",
    "    pred_list = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "    pred_list = ['pred_1']\n",
    "    uq_list = []\n",
    "    for p in pred_list: \n",
    "        uq_auc = calculate_auc(df_pred['gt'].astype(int) == df_pred_baseline[p].astype(int), uq_metric_baseline)\n",
    "        uq_list.append(uq_auc)\n",
    "        # print(uq_auc)\n",
    "    print(np.mean(uq_list), np.std(uq_list))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No. The patient will not be discharged within ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No. The patient is 85 years old and has underg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pred_1  pred_2  pred_3  \\\n",
       "0                                                   0       0       0   \n",
       "1                                                   0       0       0   \n",
       "2                                                   0       0       0   \n",
       "3   No. The patient will not be discharged within ...       0       0   \n",
       "4                                                   0       0       0   \n",
       "..                                                ...     ...     ...   \n",
       "95                                                  0       1       1   \n",
       "96                                                  1       1       0   \n",
       "97                                                  0       0       0   \n",
       "98                                                  1       1       1   \n",
       "99                                                  1       0       0   \n",
       "\n",
       "                                               pred_4  pred_5  \n",
       "0                                                   0       0  \n",
       "1                                                   0       0  \n",
       "2                                                   0       0  \n",
       "3   No. The patient is 85 years old and has underg...       0  \n",
       "4                                                   0       0  \n",
       "..                                                ...     ...  \n",
       "95                                                  1       1  \n",
       "96                                                  1       1  \n",
       "97                                                  0       1  \n",
       "98                                                  1       1  \n",
       "99                                                  0       0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
