{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# explore the data\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "from loguru import logger\n",
    "from ehrshot.utils import LABELING_FUNCTION_2_PAPER_NAME\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from femr.datasets import PatientDatabase\n",
    "import femr\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one line of code to configure the patient database\n",
    "def configure_database(path_to_database: str) -> PatientDatabase:\n",
    "    return PatientDatabase(path_to_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_events(events, code_description):\n",
    "    # Organize events by code\n",
    "    grouped_events = {}\n",
    "    for event in events:\n",
    "        if event.code in grouped_events:\n",
    "            grouped_events[event.code].append(event)\n",
    "        else:\n",
    "            grouped_events[event.code] = [event]\n",
    "\n",
    "    # Mock database dictionary to translate medical codes\n",
    "\n",
    "    descriptions = []\n",
    "    for code, group in grouped_events.items():\n",
    "        # Start the description for this group\n",
    "        event_type = code_description.get(code, code)\n",
    "        times = ', '.join(set(e.start.strftime('%B %d, %Y, %H:%M') for e in group))\n",
    "        # description = f\"On {times}, {len(group)} events categorized under the code '{code}' ({event_type}) occurred.\"\n",
    "\n",
    "        # description = f\"On {times}, {len(group)} {group[0].omop_table} medical events ({event_type}) occurred.\"\n",
    "\n",
    "        omop_code = group[0].omop_code\n",
    "        if omop_code:\n",
    "            if '_' in omop_code:\n",
    "                omop_code = omop_code.replace('_', ' ')\n",
    "            description = f\"{len(group)} {omop_code} events:'{event_type}' recorded\"\n",
    "        else:\n",
    "            description = f\"{len(group)} events:'{event_type}' recorded\"\n",
    "        # Check if any event in the group has a value\n",
    "        values = set(e.value for e in group if e.value is not None)\n",
    "        if values:\n",
    "            description += f\" with values: {', '.join(map(str, values))}.\"\n",
    "\n",
    "        # description += f\" These events were recorded in the '{group[0].omop_table}' table.\"\n",
    "        \n",
    "        descriptions.append(description)\n",
    "    \n",
    "    # Combine all descriptions into a single paragraph\n",
    "    return ' \\n'.join(descriptions)\n",
    "\n",
    "def add_patient_age(prediction_time_datatime_format, database, patient_id, text):\n",
    "    time_lap = prediction_time_datatime_format.date() - database.get_patient_birth_date(patient_id)\n",
    "    patient_age = time_lap.days // 365\n",
    "    date = prediction_time_datatime_format.date().strftime('%B %d, %Y')\n",
    "    return f\"The patient was {patient_age} years old at the prediction time.\\n\" + text\n",
    "\n",
    "def find_closest_under_datetime(datetime_list, target_datetime):\n",
    "    # Filter the list to only include datetimes that are less than the target datetime\n",
    "    filtered_list = [dt for dt in datetime_list if dt <= target_datetime]\n",
    "    \n",
    "    # Handle case where there might be no earlier datetimes\n",
    "    if not filtered_list:\n",
    "        return None  # Or handle this case as appropriate in your context\n",
    "    \n",
    "    # Calculate the time differences for the filtered list\n",
    "    time_differences = [target_datetime - dt for dt in filtered_list]\n",
    "    \n",
    "    # Find the index of the minimum time difference in the filtered list\n",
    "    min_difference_index = time_differences.index(min(time_differences))\n",
    "    \n",
    "    # Get the original index from the full list\n",
    "    closest_datetime = filtered_list[min_difference_index]\n",
    "    original_index = datetime_list.index(closest_datetime)\n",
    "    \n",
    "    return original_index\n",
    "\n",
    "def add_demographic_info(patient_events, code_description, final_description):\n",
    "    person_info_events = patient_events[0:10]\n",
    "    person_info_code_list = []\n",
    "    person_info_description = 'The patient has the following demographic information: '\n",
    "    for e in person_info_events:\n",
    "        if e.omop_table == 'person':\n",
    "            if e.code != 'SNOMED/3950001':\n",
    "                person_info_code_list.append(e.code)\n",
    "    for i in range(len(person_info_code_list)):\n",
    "        c = person_info_code_list[i]\n",
    "        if i != len(person_info_code_list) - 1:\n",
    "            person_info_description += f'{code_description[c]},'\n",
    "        else:\n",
    "            person_info_description += f'{code_description[c]}.' + '\\n'\n",
    "    return person_info_description + final_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = configure_database(\"EHRSHOT_ASSETS/femr/extract\")\n",
    "\n",
    "with open('ehrshot_code_description.json', 'r') as f:\n",
    "    code_description = json.load(f)\n",
    "\n",
    "df_common = pd.read_csv('white_box_common_data/new_diagnose_blood.csv')\n",
    "\n",
    "for column in df_common.columns:\n",
    "    if df_common[column].dtype == 'bool':\n",
    "        df_common[column] = df_common[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2987 [00:00<01:50, 26.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2987/2987 [01:06<00:00, 44.79it/s]\n"
     ]
    }
   ],
   "source": [
    "final_description_list = []\n",
    "num_events = 300\n",
    "for i in tqdm(range(len(df_common))):\n",
    "# for i in range(1):\n",
    "    patient_id = df_common.loc[i].patient_id\n",
    "    prediction_time = df_common.loc[i].prediction_time\n",
    "    prediction_time = datetime.datetime.fromisoformat(prediction_time)\n",
    "    patient_femr_object = database[patient_id]\n",
    "    assert patient_id == patient_femr_object.patient_id\n",
    "    patient_events = list(patient_femr_object.events)\n",
    "\n",
    "    all_event = []\n",
    "    #     time_start = e.start\n",
    "    #     if time_start == prediction_time + datetime.timedelta(minutes=1):\n",
    "    #         all_event.append(e)\n",
    "    # if len(all_event) == 0:\n",
    "    #     print(i)\n",
    "    time_list = [e.start for e in patient_events]\n",
    "    time_idx = find_closest_under_datetime(time_list, prediction_time)\n",
    "    if time_idx > num_events:\n",
    "        start_index = time_idx - num_events\n",
    "    else:\n",
    "        start_index = 3\n",
    "    \n",
    "    all_event = patient_events[start_index:time_idx+1]\n",
    "    all_time = time_list[start_index:time_idx+1]\n",
    "\n",
    "    paired_list = list(zip(all_time, all_event))\n",
    "    grouped = [(date, [event for _, event in group]) for date, group in groupby(paired_list, key=lambda x: x[0].date())]\n",
    "    final_description = ''\n",
    "    for temp_date, temp_group in grouped:\n",
    "        current_date = temp_date.strftime('%B %d, %Y')\n",
    "        description = describe_events(temp_group, code_description)\n",
    "        final_description += f'At {current_date}:\\n' + description + '\\n'\n",
    "    final_description = add_demographic_info(patient_events, code_description, final_description)\n",
    "    final_description = add_patient_age(prediction_time, database, patient_id, final_description)\n",
    "\n",
    "    final_description_list.append(final_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common['description'] = final_description_list\n",
    "\n",
    "df_common.to_csv('new_diagnose_blood_patient_description_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['value_new_hypertension','value_new_hyperlipidemia', 'value_new_pancan', 'value_new_celiac', 'value_new_lupus', 'value_new_acutemi']\n",
    "# df = df_common.loc[:, ['value_new_hypertension','value_new_hyperlipidemia', 'value_new_pancan', 'value_new_celiac', 'value_new_lupus', 'value_new_acutemi']]\n",
    "df = df_common.loc[:, ['value_new_hypertension','value_new_hyperlipidemia', 'value_new_acutemi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_idx_hypertension = np.where(df_common['value_new_hypertension'] == 1)[0]\n",
    "pos_idx_hyperlipidemia = np.where(df_common['value_new_hyperlipidemia'] == 1)[0]\n",
    "# pos_idx_pancan = np.where(df_common['value_new_pancan'] == 1)[0]\n",
    "# pos_idx_celiac = np.where(df_common['value_new_celiac'] == 1)[0]\n",
    "# pos_idx_lupus = np.where(df_common['value_new_lupus'] == 1)[0]\n",
    "pos_idx_acutemi = np.where(df_common['value_new_acutemi'] == 1)[0]\n",
    "\n",
    "def sample_from_array(arr, n=12):\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    return np.random.choice(arr, n, replace=False)  # Set replace=False to sample without replacement\n",
    "\n",
    "# Sampling from each array\n",
    "samples_hypertension = sample_from_array(pos_idx_hypertension)\n",
    "samples_hyperlipidemia = sample_from_array(pos_idx_hyperlipidemia)\n",
    "samples_pancan = sample_from_array(pos_idx_pancan)\n",
    "samples_celiac = sample_from_array(pos_idx_celiac)\n",
    "samples_lupus = sample_from_array(pos_idx_lupus)\n",
    "samples_acutemi = sample_from_array(pos_idx_acutemi)\n",
    "\n",
    "# Concatenate all samples into a single array\n",
    "all_samples_idx = np.concatenate([\n",
    "    samples_hypertension,\n",
    "    samples_hyperlipidemia,\n",
    "    samples_pancan,\n",
    "    samples_celiac,\n",
    "    samples_lupus,\n",
    "    samples_acutemi\n",
    "])\n",
    "all_samples_idx.sort()\n",
    "all_samples_idx = np.unique(all_samples_idx)\n",
    "all_samples_idx.shape\n",
    "all_index = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m excluded_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(\u001b[43mall_index\u001b[49m, all_samples_idx)\n\u001b[1;32m      2\u001b[0m sampled__reset_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(excluded_array, (\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_samples_idx)), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_index' is not defined"
     ]
    }
   ],
   "source": [
    "excluded_array = np.setdiff1d(all_index, all_samples_idx)\n",
    "sampled_reset_values = np.random.choice(excluded_array, (100 - len(all_samples_idx)), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2794, step=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHRSHOT_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
